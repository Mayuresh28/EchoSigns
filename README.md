# EchoSigns

SignSpeak is an advanced sign language translator designed to facilitate seamless communication for Deaf and Mute individuals. Using real-time video analysis and machine learning, it translates sign language gestures into text and spoken words.

Features
Real-Time Translation: Converts sign language gestures into text and speech.
User-Friendly Interface: Intuitive design for easy interaction.
Multi-Environment Use: Suitable for daily conversations, education, and healthcare.
Customizable: Easy to adapt to different sign languages and gestures.

Installation
Clone the Repository
git clone https://github.com/yourusername/signspeak.git
cd signspeak

Install Dependencies
Ensure you have Python 3.7 or higher installed. Install the required libraries using:
pip install -r requirements.txt

Download Model
Place your trained model (model.p) in the project directory.

Usage
Run the Application
python inference_classifier.py


Interact with the Application

Point the camera at your hand gestures.
See the translated text and hear the spoken words in real-time.
Use the "Clear" and "Speak" buttons to manage and vocalize detected text.
Configuration
Model File: Ensure model.p is correctly placed in the project directory.
Button Coordinates: Adjust the button coordinates in the code as needed.
Contributing
Feel free to submit issues or pull requests. For major changes, please open an issue first to discuss what you would like to change.


Contact
For questions or support, please contact mayureshmuluk28@gmail.com.

